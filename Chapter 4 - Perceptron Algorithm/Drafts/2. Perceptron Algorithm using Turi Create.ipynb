{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = turicreate.SFrame('./emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_counts'] = turicreate.text_analytics.count_words(data['text'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = {}\n",
    "for email in data:\n",
    "    for word in email['text'].split():\n",
    "        if word in count_words:\n",
    "            count_words[word] += 1\n",
    "        else:\n",
    "            count_words[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_popular_words(dictionary, min_appearances):\n",
    "    trimmed_dictionary = {}\n",
    "    popular_words = trim(count_words, min_appearances).keys()\n",
    "    for word in dictionary.keys():\n",
    "        if word in popular_words:\n",
    "            trimmed_dictionary[word] = dictionary[word]\n",
    "    return trimmed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [10, 100, 1000, 10000, 100000]:\n",
    "    data['word_counts_'+str(i)] = data['word_counts'].apply(lambda x:pick_popular_words(x, i))\n",
    "#data['word_counts_10'] = data['word_counts'].apply(lambda x:pick_popular_words(x,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print np.mean([len(x) for x in data['word_counts']])\n",
    "print np.mean([len(x) for x in data['word_counts_10']])\n",
    "print np.mean([len(x) for x in data['word_counts_100']])\n",
    "print np.mean([len(x) for x in data['word_counts_1000']])\n",
    "print np.mean([len(x) for x in data['word_counts_10000']])\n",
    "print np.mean([len(x) for x in data['word_counts_100000']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.random_split(0.8)\n",
    "print len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = turicreate.logistic_classifier.create(train, features=['word_counts'], target='spam', verbose=False)\n",
    "model_10 = turicreate.logistic_classifier.create(train, features=['word_counts_10'], target='spam', verbose=False)\n",
    "model_100 = turicreate.logistic_classifier.create(train, features=['word_counts_100'], target='spam', verbose=False)\n",
    "model_1000 = turicreate.logistic_classifier.create(train, features=['word_counts_1000'], target='spam', verbose=False)\n",
    "model_10000 = turicreate.logistic_classifier.create(train, features=['word_counts_10000'], target='spam', verbose=False)\n",
    "model_100000 = turicreate.logistic_classifier.create(train, features=['word_counts_100000'], target='spam', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.evaluate(test)['auc']\n",
    "print model_10.evaluate(test)['auc']\n",
    "print model_100.evaluate(test)['auc']\n",
    "print model_1000.evaluate(test)['auc']\n",
    "print model_10000.evaluate(test)['auc']\n",
    "print model_100000.evaluate(test)['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.coefficients.sort('value', ascending=False)\n",
    "print model_10.coefficients.sort('value', ascending=False)\n",
    "print model_100.coefficients.sort('value', ascending=False)\n",
    "print model_1000.coefficients.sort('value', ascending=False)\n",
    "print model_10000.coefficients.sort('value', ascending=False)\n",
    "print model_100000.coefficients.sort('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.coefficients.sort('value', ascending=True)\n",
    "print model_10.coefficients.sort('value', ascending=True)\n",
    "print model_100.coefficients.sort('value', ascending=True)\n",
    "print model_1000.coefficients.sort('value', ascending=True)\n",
    "print model_10000.coefficients.sort('value', ascending=True)\n",
    "print model_100000.coefficients.sort('value', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word(dictionary, word):\n",
    "    if word in dictionary:\n",
    "        return dictionary[word]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['viagra', 'advertisement']:\n",
    "    data[word] = data['word_counts'].apply(lambda x:count_word(x, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.random_split(0.8)\n",
    "print len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_word_model = turicreate.logistic_classifier.create(train, features=['viagra', 'advertisement'], target='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_word_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_word_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
