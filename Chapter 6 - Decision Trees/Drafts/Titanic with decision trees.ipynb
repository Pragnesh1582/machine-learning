{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic data with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic_data = pd.read_csv('titanic_data.csv')\n",
    "titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(titanic_data[features])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "X['Sex'] = lb.fit_transform(X['Sex'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Embarked'] = lb.fit_transform(X['Embarked'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Categorized_Age'] = lb.fit_transform(X['Categorized_Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(\"Cabin\", axis=1)\n",
    "X = X.drop(\"Ticket\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Title'] = lb.fit_transform(X['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(titanic_data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X,y)\n",
    "dt.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "dot_data = dt.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"dt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in titanic_data.column_names() if f != 'Name' and f != 'Survived' and f!= 'PassengerId']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    print (f, type(titanic_data[f][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(l):\n",
    "    # Returns gini index of a list of values\n",
    "    print (1 - np.dot(l,l)*1.0/(sum(l))**2)\n",
    "def entropy(l):\n",
    "    # Returns the entropy of a list of values\n",
    "    return np.dot(l, np.log2(l))/sum(l)\n",
    "\n",
    "def classes_count(feature):\n",
    "    # Given a column with discrete fields, it returns the dictionary\n",
    "    # containing the fields and their number of appearances\n",
    "    column = titanic_data[feature]\n",
    "    classes = {}\n",
    "    for element in column:\n",
    "        if element in classes.keys():\n",
    "            classes[element] += 1\n",
    "        else:\n",
    "            classes[element] = 1\n",
    "    return classes\n",
    "\n",
    "def pick_highest_class(column):\n",
    "    # Given a column, it returns the feature that splits the column\n",
    "    # with the highest gini impurity, and the two SFrames split by that feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[classes_count('Title')[key] for key in classes_count('Title')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Fare'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "enc.fit(X)\n",
    "\n",
    "OneHotEncoder(categorical_features=None, categories=None,\n",
    "    #drop=None,\n",
    "    #dtype=<'numpy.float64'>,\n",
    "    handle_unknown='ignore',\n",
    "    n_values=None, sparse=True)\n",
    "enc.categories_\n",
    "#[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
    "enc.transform([['Female', 1], ['Male', 4]]).toarray()\n",
    "#array([[1., 0., 1., 0., 0.],\n",
    "#       [0., 1., 0., 0., 0.]])\n",
    "enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
    "#array([['Male', 1],\n",
    "#       [None, 2]], dtype=object)\n",
    "enc.get_feature_names()\n",
    "#array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)\n",
    "drop_enc = OneHotEncoder(drop='first').fit(X)\n",
    "drop_enc.categories_\n",
    "#[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
    "drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
    "#array([[0., 0., 0.],\n",
    "#       [1., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder(categorical_features=None, categories=None, handle_unknown='ignore', n_values=None, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(enc.transform([['Female', 1], ['Male', 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle walkthrough\n",
    "https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = './train.csv'\n",
    "path_test = './test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_raw = pd.read_csv(path_train)\n",
    "train_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1,1,figsize=(20, 6))\n",
    "plot = sns.catplot(x=\"Embarked\", y=\"Fare\", hue=\"Sex\", data=train_df_raw, palette=('Set1'), kind=\"bar\", ax=axes)\n",
    "plt.close(plot.fig)\n",
    "plt.show()\n",
    "display(train_df_raw[train_df_raw['Embarked'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot some histograms to have a previzualisation of some of the data ...\n",
    "train_df_raw.drop(['PassengerId'], 1).hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    processed_df = df\n",
    "        \n",
    "    ########## Deal with missing values ##########\n",
    "    \n",
    "    # As we saw before, the two missing values for embarked columns can be replaced by 'C' (Cherbourg)\n",
    "    processed_df['Embarked'].fillna('C', inplace=True)\n",
    "    \n",
    "    # We replace missing ages by the mean age of passengers who belong to the same group of class/sex/family\n",
    "    processed_df['Age'] = processed_df.groupby(['Pclass','Sex','Parch','SibSp'])['Age'].transform(lambda x: x.fillna(x.mean()))\n",
    "    processed_df['Age'] = processed_df.groupby(['Pclass','Sex','Parch'])['Age'].transform(lambda x: x.fillna(x.mean()))\n",
    "    processed_df['Age'] = processed_df.groupby(['Pclass','Sex'])['Age'].transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    # We replace the only missing fare value for test dataset and the missing values of the cabin column\n",
    "    processed_df['Fare'] = processed_df['Fare'].interpolate()\n",
    "    processed_df['Cabin'].fillna('U', inplace=True)\n",
    "    \n",
    "    ########## Feature engineering on columns ##########\n",
    "    \n",
    "    # Create a Title column from name column\n",
    "    processed_df['Title'] = pd.Series((name.split('.')[0].split(',')[1].strip() for name in train_df_raw['Name']), index=train_df_raw.index)\n",
    "    processed_df['Title'] = processed_df['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    processed_df['Title'] = processed_df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    processed_df['Title'] = processed_df['Title'].replace('Mme', 'Mrs')\n",
    "    processed_df['Title'] = processed_df['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})\n",
    "    \n",
    "    # Filling Age missing values with mean age of passengers who have the same title\n",
    "    processed_df['Age'] = processed_df.groupby(['Title'])['Age'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    # Transform categorical variables to numeric variables\n",
    "    processed_df['Sex'] = processed_df['Sex'].map({'male': 0, 'female': 1})\n",
    "    processed_df['Embarked'] = processed_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    \n",
    "    # Create a Family Size, Is Alone, Child and Mother columns\n",
    "    processed_df['FamillySize'] = processed_df['SibSp'] + processed_df['Parch'] + 1\n",
    "    processed_df['FamillySize'][processed_df['FamillySize'].between(1, 5, inclusive=False)] = 2\n",
    "    processed_df['FamillySize'][processed_df['FamillySize']>5] = 3\n",
    "    processed_df['IsAlone'] = np.where(processed_df['FamillySize']!=1, 0, 1)\n",
    "    processed_df['IsChild'] = processed_df['Age'] < 18\n",
    "    processed_df['IsChild'] = processed_df['IsChild'].astype(int)\n",
    "    \n",
    "    # Modification of cabin column to keep only the letter contained corresponding to the deck of the boat\n",
    "    processed_df['Cabin'] = processed_df['Cabin'].str[:1]\n",
    "    processed_df['Cabin'] = processed_df['Cabin'].map({cabin: p for p, cabin in enumerate(set(cab for cab in processed_df['Cabin']))})\n",
    "    \n",
    "    # Create a ticket survivor column which is set to 1 if an other passenger with the same ticket survived and 0 else\n",
    "    # Note : this implementation is ugly and unefficient, if sombody found a way to do it easily with pandas (it must be a way), please comment the kernel with your solution !\n",
    "    processed_df['TicketSurvivor'] = pd.Series(0, index=processed_df.index)\n",
    "    tickets = processed_df['Ticket'].value_counts().to_dict()\n",
    "    for t, occ in tickets.items():\n",
    "        if occ != 1:\n",
    "            table = train_df_raw['Survived'][train_df_raw['Ticket'] == t]\n",
    "            if sum(table) != 0:\n",
    "                processed_df['TicketSurvivor'][processed_df['Ticket'] == t] = 1\n",
    "    \n",
    "    # These two columns are not useful anymore\n",
    "    processed_df = processed_df.drop(['Name', 'Ticket', 'PassengerId'], 1)    \n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide the train dataset in two datasets to evaluate perfomance of the machine learning models we'll use\n",
    "train_df = train_df_raw.copy()\n",
    "X = train_df.drop(['Survived'], 1)\n",
    "Y = train_df['Survived']\n",
    "\n",
    "X = preprocess_data(X)\n",
    "# We scale our data, it is essential for a smooth working of the models. Scaling means that each columns as a 0 mean and a 1 variance\n",
    "sc = StandardScaler()\n",
    "X = pd.DataFrame(sc.fit_transform(X.values), index=X.index, columns=X.columns)\n",
    "    \n",
    "# Split dataset for model testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_split=15, min_samples_leaf=20, random_state=42)\n",
    "dt.fit(X_train, Y_train)\n",
    "dt_prediction = dt.predict(X_test)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, dt_prediction)\n",
    "display_confusion_matrix(Y_test, dt_prediction, score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = titanic_data.remove_columns(['Name', 'Ticket', 'Cabin', 'Age'])\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dataset = pd.DataFrame({\n",
    "    'Gender': ['Female','Female','Male','Female','Male','Male'],\n",
    "    'Age': [15, 25, 32, 35, 12, 14],\n",
    "    'App': ['Atom Count', 'Check Mate Mate', 'Beehive Finder', 'Check Mate Mate', 'Atom Count', 'Atom Count']})\n",
    "app_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dataset_one_hot = pd.DataFrame(\n",
    "    {'Gender_Female':[1,1,0,1,0,0],\n",
    "     'Gender_Male':[0,0,1,0,1,1],\n",
    "     'Age_Young':[1,0,0,0,1,1],\n",
    "     'Age_Old':[0,1,1,1,0,0],\n",
    "     'App_Atom_Count':[1,0,0,0,1,1],\n",
    "     'App_Beehive_Finder':[0,0,1,0,0,0],\n",
    "     'App_Check_Mate_Mate':[0,1,0,1,0,0]})\n",
    "app_dataset_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = app_dataset_one_hot[['Gender_Female','Gender_Male','Age_Old','Age_Young']]\n",
    "y = app_dataset_one_hot[['App_Atom_Count','App_Beehive_Finder','App_Check_Mate_Mate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X,y)\n",
    "dt.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dataset = pd.DataFrame({\n",
    "    'Gender_Female':[1,1,0,1,0,0],\n",
    "    'Gender_Male':[0,0,1,0,1,1],\n",
    "    'Age': [15, 25, 32, 35, 12, 14],\n",
    "    'App': ['Atom Count', 'Check Mate Mate', 'Beehive Finder', 'Check Mate Mate', 'Atom Count', 'Atom Count']})\n",
    "print(app_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = app_dataset_new[['Age','Gender_Female','Gender_Male']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_model = DecisionTreeClassifier()\n",
    "app_model.fit(features, labels)\n",
    "app_model.score(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(new_dt, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini index calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['A', 'A', 'A', 'C', 'B', 'C']\n",
    "def counts(elements):\n",
    "    classes = {}\n",
    "    for element in elements:\n",
    "        if element in classes:\n",
    "            classes[element] += 1\n",
    "        else:\n",
    "            classes[element] = 1\n",
    "    return [classes[e] for e in classes]\n",
    "counts(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(counts):\n",
    "    n = sum(counts)\n",
    "    return 1 - sum([p_i**2/n**2 for p_i in counts])\n",
    "gini(counts(elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting age on 13\n",
    "gini(counts(elements)) - (gini([1])*1/6 + gini([2,1,2])*5/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting age on 14.5\n",
    "gini(counts(elements)) - (gini([2])*2/6 + gini([1,1,2])*4/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting age on 20\n",
    "gini(counts(elements)) - (gini([3])*3/6 + gini([1,2])*3/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting age on 27\n",
    "gini(counts(elements)) - (gini([3,1])*4/6 + gini([1,1])*2/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting age on 33\n",
    "gini(counts(elements)) - (gini([3,1,1])*5/6 + gini([1])*1/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dataset = pd.DataFrame({\n",
    "    'Lottery':[7,3,9,1,2,4,1,3,6,7,8,9],\n",
    "    'Sale':[1,2,3,3,6,7,9,10,5,8,4,6],\n",
    "    'Spam': ['no','no','no','no','no','no','yes','yes','yes','yes','yes','yes']})\n",
    "spam_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = spam_dataset[['Lottery', 'Sale']]\n",
    "labels = spam_dataset['Spam']\n",
    "spam_decision_tree = DecisionTreeClassifier()\n",
    "spam_decision_tree.fit(X,y)\n",
    "spam_decision_tree.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(X['Lottery'][:6], X['Sale'][:6])\n",
    "plt.scatter(X['Lottery'][6:], X['Sale'][6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(spam_decision_tree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
